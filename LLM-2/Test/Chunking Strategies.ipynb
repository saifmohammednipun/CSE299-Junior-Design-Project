{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e669aec7-14db-482b-8d03-0214bfae7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Ensure the environment variables are set\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "huggingface_api_key = os.getenv('HUGGINGFACE_API_KEY')\n",
    "\n",
    "if not langchain_api_key:\n",
    "    raise ValueError(\"LANGCHAIN_API_KEY is not set in the environment variables.\")\n",
    "if not huggingface_api_key:\n",
    "    raise ValueError(\"HUGGINGFACE_API_KEY is not set in the environment variables.\")\n",
    "\n",
    "# Set environment variables for the application\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_API_KEY'] = langchain_api_key\n",
    "os.environ['HUGGINGFACE_API_KEY'] = huggingface_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c2fc9b9-6d90-42c3-a079-1101d4f65106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c15ab7-3089-4689-a4f4-9bc0fa2b3e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DIABETES CARE \\nBADAS Guideline 2019 \\n          \\n  \\n   \\n  \\n   P|) \\nDAS GUELINE ON Man \\nDELIT IGEMEN \\n  \\nA Joint Initiative of \\nDiabetic Association of Bangladesh \\nNCDC Program, Directorate General of Health Services'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Documents (use PyPDFLoader for PDF)\n",
    "file_path = r\"C:\\Users\\User\\Desktop\\NSU\\CSE299 Materials\\LLM\\Dataset\\Diabetes_Care_BADAS_guideline2019-3.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "\n",
    "docs[0].page_content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c6bf0ac-0c50-48ab-b5bd-34b968d1644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Chunking Functions\n",
    "from chunking_evaluation.chunking import (\n",
    "    ClusterSemanticChunker,\n",
    "    LLMSemanticChunker,\n",
    "    FixedTokenChunker,\n",
    "    RecursiveTokenChunker,\n",
    "    KamradtModifiedChunker\n",
    ")\n",
    "# Additional Dependencies\n",
    "import tiktoken\n",
    "from chromadb.utils import embedding_functions\n",
    "import spacy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bac174-af17-422c-91ff-55c368f54009",
   "metadata": {},
   "source": [
    "# Helper Function for Analyzing Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcf8587a-e79e-42e9-a6d4-3664bfc9df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_chunks(chunks, use_tokens=False):\n",
    "    # Print the chunks of interest\n",
    "    print(\"\\nNumber of Chunks:\", len(chunks))\n",
    "    print(\"\\n\", \"=\"*50, \"200th Chunk\", \"=\"*50,\"\\n\", chunks[199])\n",
    "    print(\"\\n\", \"=\"*50, \"201st Chunk\", \"=\"*50,\"\\n\", chunks[200])\n",
    "    \n",
    "    chunk1, chunk2 = chunks[199], chunks[200]\n",
    "    \n",
    "    if use_tokens:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        tokens1 = encoding.encode(chunk1)\n",
    "        tokens2 = encoding.encode(chunk2)\n",
    "        \n",
    "        # Find overlapping tokens\n",
    "        for i in range(len(tokens1), 0, -1):\n",
    "            if tokens1[-i:] == tokens2[:i]:\n",
    "                overlap = encoding.decode(tokens1[-i:])\n",
    "                print(\"\\n\", \"=\"*50, f\"\\nOverlapping text ({i} tokens):\", overlap)\n",
    "                return\n",
    "        print(\"\\nNo token overlap found\")\n",
    "    else:\n",
    "        # Find overlapping characters\n",
    "        for i in range(min(len(chunk1), len(chunk2)), 0, -1):\n",
    "            if chunk1[-i:] == chunk2[:i]:\n",
    "                print(\"\\n\", \"=\"*50, f\"\\nOverlapping text ({i} chars):\", chunk1[-i:])\n",
    "                return\n",
    "        print(\"\\nNo character overlap found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be74c78b-1920-430b-abf3-de1aeaa0cc00",
   "metadata": {},
   "source": [
    "# Character Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71bbb01e-392b-43fb-9c09-62c03da7a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = \" \".join([doc.page_content for doc in docs])\n",
    "\n",
    "def chunk_text(docs, chunk_size, overlap):\n",
    "    chunks = []\n",
    "    stride = chunk_size - overlap\n",
    "    current_idx = 0\n",
    "    \n",
    "    while current_idx < len(all_text):\n",
    "        # Take chunk_size characters starting from current_idx\n",
    "        chunk = docs[current_idx:current_idx + chunk_size]\n",
    "        if not chunk:  # Break if we're out of text\n",
    "            break\n",
    "        chunks.append(chunk)\n",
    "        current_idx += stride  # Move forward by stride\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3985977d-16bd-4904-84dc-445b37e825e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Chunks: 296\n",
      "\n",
      " ================================================== 200th Chunk ================================================== \n",
      " t should be done annually with 75g 2h OGTT or \n",
      "A1C. If prediabetes, reassessment should be done 6 monthly and should be put \n",
      "on MNT or metformin should be followed by standard protocol. \n",
      "Low dose estrogen-progesterone can be offered for contraception. \n",
      "Progesterone only preparation increases risk of vascular complications. \n",
      "Screening for all components of metabolic syndrome should be offered. \n",
      "Throughout the period of breast feeding all types of insulins and metformin \n",
      "can be safely used in lactating women. Women with preprgnancy diabetes \n",
      "who are breastfeeding should continue to avoid any drugs for the treatment of \n",
      "diabetes complications that were discontinued for safety reasons in the \n",
      "pre-conception period. \n",
      "6.2 Diabetes in children \n",
      "Diabetes mellitus in childhood and adolescence is mo\n",
      "\n",
      " ================================================== 201st Chunk ================================================== \n",
      " oughout the period of breast feeding all types of insulins and metformin \n",
      "can be safely used in lactating women. Women with preprgnancy diabetes \n",
      "who are breastfeeding should continue to avoid any drugs for the treatment of \n",
      "diabetes complications that were discontinued for safety reasons in the \n",
      "pre-conception period. \n",
      "6.2 Diabetes in children \n",
      "Diabetes mellitus in childhood and adolescence is most often type 1 diabetes. \n",
      "But they have the chance of developing other specific types of diabetes. \n",
      "Now-a-days type 2 diabetes is developing in the young at a very high rate. \n",
      "Diagnostic and management issues in this group of population are a bit \n",
      "different from that of adult. \n",
      "Type 2 diabetes mellitus in children is relatively less common than in adult. But \n",
      "nowadays it is being reported more fr\n",
      "\n",
      " ================================================== \n",
      "Overlapping text (400 chars): oughout the period of breast feeding all types of insulins and metformin \n",
      "can be safely used in lactating women. Women with preprgnancy diabetes \n",
      "who are breastfeeding should continue to avoid any drugs for the treatment of \n",
      "diabetes complications that were discontinued for safety reasons in the \n",
      "pre-conception period. \n",
      "6.2 Diabetes in children \n",
      "Diabetes mellitus in childhood and adolescence is mo\n"
     ]
    }
   ],
   "source": [
    "character_overlap_chunks = chunk_text(all_text, chunk_size=800, overlap=400)\n",
    "\n",
    "analyze_chunks(character_overlap_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa392d30-d666-45f7-9ffb-caf4688dc46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
